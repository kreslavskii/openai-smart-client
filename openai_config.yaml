# Configuration for universal OpenAI API client
# Supported models: GPT-4o, GPT-4.1, O-series, Search models, Deep Research
# Path to file can be specified via OPENAI_CONFIG_PATH environment variable
# or passed directly when initializing the client

# API key is taken ONLY from OPENAI_API_KEY environment variable
# NEVER store API keys in configuration files!

# =============================================================================
# Main Model Parameters
# =============================================================================

model: "gpt-4o"  # Default model (see model list below)
temperature: 0.7  # From 0 to 2. Low values = deterministic responses

# Token parameters
max_completion_tokens: null  # Current parameter (max tokens in response)
max_tokens: null  # Deprecated parameter, kept for backward compatibility

# Connection parameters
timeout: 60.0  # Request timeout in seconds
base_url: null  # Custom base URL (for compatible APIs)
organization: null  # OpenAI organization ID

# Retry logic parameters (exponential backoff with jitter)
max_retries: 3  # Number of retry attempts on errors
retry_delay: 1.0  # Base delay between attempts in seconds
max_retry_delay: 60.0  # Upper delay limit (caps exponential growth)

# =============================================================================
# Web Search Configuration (for Responses API)
# =============================================================================

web_search:
  tool_choice: "auto"  # "auto" | "required" | "none"
  search_context_size: "medium"  # "low" | "medium" | "high"
  # user_location:  # Location for result personalization
  #   type: "approximate"
  #   country: "US"
  #   city: "New York"
  #   region: "New York"

# =============================================================================
# OpenAI Model Reference
# =============================================================================
#
# STANDARD MODELS (Chat Completions API):
# ─────────────────────────────────────────────────────────────────────────────
# Alias              │ Snapshot                  │ Input $/1M │ Output $/1M
# ─────────────────────────────────────────────────────────────────────────────
# gpt-4o             │ gpt-4o-2024-11-20         │ 2.50       │ 10.00
# gpt-4o-mini        │ gpt-4o-mini-2024-07-18    │ 0.15       │ 0.60
# gpt-4.1            │ gpt-4.1-2025-04-14        │ 2.00       │ 8.00
# gpt-4.1-mini       │ gpt-4.1-mini-2025-04-14   │ 0.40       │ 1.60
# o4-mini            │ o4-mini-2025-04-16        │ 1.10       │ 4.40
# o3-mini            │ o3-mini-2025-01-31        │ 1.10       │ 4.40
# ─────────────────────────────────────────────────────────────────────────────
#
# SEARCH MODELS (Chat Completions API with built-in web search):
# ─────────────────────────────────────────────────────────────────────────────
# gpt-4o-search-preview       │ Available without org verification
# gpt-4o-mini-search-preview  │ Available without org verification
# gpt-5-search-api            │ May require org verification
# ─────────────────────────────────────────────────────────────────────────────
#
# DEEP RESEARCH MODELS (Responses API, long-running agentic search):
# ─────────────────────────────────────────────────────────────────────────────
# o3-deep-research            │ Requires at least one data source
# o4-mini-deep-research       │ Requires at least one data source
# ─────────────────────────────────────────────────────────────────────────────
#
# WEB SEARCH METHODS:
#
# 1. Responses API + web_search tool (recommended):
#    - Use call_openai_web_search() or client.call_web_search()
#    - Works with any standard model (gpt-4o, gpt-4.1, o4-mini, etc.)
#    - Model decides whether to search (tool_choice="auto")
#    - Or forced search (tool_choice="required")
#
# 2. Chat Completions + search models:
#    - Use call_openai(model="gpt-4o-search-preview")
#    - Web search is built into the model, no tools required
#
# 3. Deep Research (long-running agentic search):
#    - Models o3-deep-research, o4-mini-deep-research
#    - For complex research tasks
#
# =============================================================================

# Additional API parameters (optional, can be overridden at call time)
# These parameters will be used by default if not explicitly specified
defaults:
  # top_p: 1.0  # Nucleus sampling (0-1)
  # frequency_penalty: 0.0  # Frequency penalty (-2.0 to 2.0)
  # presence_penalty: 0.0  # Presence penalty (-2.0 to 2.0)
  # n: 1  # Number of alternative responses (1-128)
  # stop: null  # Stop sequences for generation
  # seed: null  # Value for deterministic results
  # response_format: null  # Response format: {"type": "json_object"} or {"type": "json_schema", "json_schema": {...}}
  # logprobs: false  # Enable log probabilities
  # top_logprobs: null  # Number of top tokens for logprobs: 0 to disable, 1-20 to enable
  # logit_bias: null  # Token probability modification: {"token_id": bias_value} where bias_value is -100 to 100
  # tools: null  # Tool list for Function Calling
  # tool_choice: "auto"  # Tool selection strategy
  # parallel_tool_calls: true  # Allow parallel function calls
  # service_tier: "auto"  # Service tier: "auto", "default", "flex", "priority"
  # store: false  # Store request for model distillation
